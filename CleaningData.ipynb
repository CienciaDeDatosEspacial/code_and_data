{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.imgur.com/zRrFdsf.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "\n",
    "Having data does not always allow you to produce some analytics right away. There is often a lot of pre processing to be done. \n",
    "\n",
    "This material is about **Cleaning**: making sure each cell has a value that could be used in your coming procedures. There are always some _impurities_ that do not allow the computer to recognize the data correctly, i.e. _commas_ instead of _periods_ and viceversa, the presence of unneeded _blanks_, irrelevant symbols (dollar, euro symbols), or non-standard symbols to represent missing values.\n",
    "\n",
    "I will use two approaches. The first one is the smart use of regular expressions (**regex**), and the second one a **divide and conquer** strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGEX VERSUS DIVIDE AND CONQUER \n",
    "\n",
    "Imagine that you request the age people in an online form. Sometimes you run into answers with issues like these:\n",
    "\n",
    "- \"It is:24\"\n",
    "- \"It is: 44\"\n",
    "- \"It is54\"\n",
    "- \"64 it is\"\n",
    "- \"I am twenty\"\n",
    "- \"The 10th I turn 21\"\n",
    "- \"I am 15 years old\"\n",
    "- \"~20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above examples, you are interested in the _age_, nothing else. The first two cases are _relatively_ easy to solve with divide and conquer, as you see a character that helps:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case1=\"It is:24\"\n",
    "case2=\"It is: 34\"\n",
    "# try 1\n",
    "case1.split(':')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try 2:\n",
    "case2.split(':')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split broke the string using \":\" and produced a _list_.  The number will be the second element. However, in _case2_ you got an extra space. You need to think about a general rule, so maybe this is better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case1.split(':')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case2.split(':')[1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using _strip()_ gets rid of the spaces around the string.  Notice _strip()_ and _split()_ are functions in **base Python**. Pandas has its **own** functions. \n",
    "\n",
    "You can use the divide and conquer as long as every string you find follows the same pattern. Imagine those values make a column in a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ages=[\"It is:24\",\"It is: 44\",\"It is54\",\n",
    "      \"64 it is\",\"I am twenty\",\"The 10th I turn 21\",\n",
    "      \"I am 15 years old\",\"~20\"]\n",
    "\n",
    "someData=pd.DataFrame({'age':ages})\n",
    "someData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use Pandas **own** strip and split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someData.age.str.split(':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or alternatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someData.age.str.split(':',expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of _expand_. This allows that each element in the list goes to a column. However, as there is **no consistent pattern**, location of the symbol \":\", you do not get a good result. The situation requires the **REGEX** approach. \n",
    "\n",
    "Using regular expressions is a great way to go when there is no pattern to apply the previous strategy; however, it takes time to learn how to build a regular expression that will serve all your especific  needs in a particular situation.\n",
    "\n",
    "In general, you need to **explore** few *regex pattern*s before deciding what to use. I recommend using **contains()** for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do each cell has a character that is not a number? (\\D)\n",
    "someData.age.str.contains(pat=r'\\D',\n",
    "                          regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do each cell has a number character? (\\d)\n",
    "someData.age.str.contains(pat=r'\\d',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is that cell?\n",
    "someData[~someData.age.str.contains(pat=r'\\d',regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there a cell where you have \n",
    "# symbols beyond [^ ] alphanumeric (\\w) or spaces (\\s)?  \n",
    "someData.age[someData.age.str.contains(pat=r'[^\\w\\s]',regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens if I erase all non numbers (\\D)?\n",
    "someData.age.str.replace(pat=r'\\D',repl='',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens if I extract consecutive numeric characters (\\d+) ?\n",
    "someData.age.str.extract(pat=r'(\\d+)',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens if I erase all \n",
    "# numbers (\\d+) followed by a texts [[a-z]+] ?\n",
    "someData.age.str.replace(pat=r'\\d+[a-z]+',\n",
    "                         repl='',\n",
    "                         regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so:\n",
    "someData.age.str.replace(pat=r'\\d+[a-z]+',\n",
    "                         repl='',\n",
    "                         regex=True).\\\n",
    "             str.extract(pat=r'(\\d+)',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using or '|'\n",
    "# ^ beginning of string\n",
    "# $ end of the string\n",
    "someData.age.str.extract(pat=r'(^\\d+|\\d+$|\\s\\d+\\s)',\n",
    "                         expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me use both results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someData['age1']=someData.age.str.replace(pat=r'\\d+[a-z]+',\n",
    "                                          repl='',\n",
    "                                          regex=True).\\\n",
    "                                str.extract(pat=r'(\\d+)',expand=True)\n",
    "\n",
    "someData['age2']=someData.age.str.extract(pat=r'(^\\d+|\\d+$|\\s\\d+\\s)',\n",
    "                         expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someData['age1'].to_list()==someData['age2'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someData['age1']==someData['age2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(someData['age1']) & set(someData['age2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(someData['age1']) ^ set(someData['age2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someData['age1'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someData['age2'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someData['age2'].str.strip().to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIA has several indicators for world countries:\n",
    "\n",
    "- See [here](https://www.cia.gov/the-world-factbook/references/guide-to-country-comparisons).\n",
    "\n",
    "Review the topics related to cleaning discussed in class, and see what may be need to clean this indicator from the CIA:\n",
    "\n",
    "- [Carbon dioxide emissions](https://www.cia.gov/the-world-factbook/field/carbon-dioxide-emissions/country-comparison)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame  \n",
    "ciaLink1=\"https://www.cia.gov/the-world-factbook/field/carbon-dioxide-emissions/country-comparison\" \n",
    "IFrame(ciaLink1, width=900, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You  need to make sure you have installed:\n",
    "\n",
    "* pandas\n",
    "* html5lib\n",
    "* lxml\n",
    "* beautifulsoup4 (or bs4)\n",
    "\n",
    "You can use **pip show** to verify (for instance, _pip show pandas_). If you have all of them, run this code to get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read web table into pandas DF\n",
    "import pandas as pd\n",
    "\n",
    "linkToFile='https://github.com/CienciaDeDatosEspacial/code_and_data/raw/main/data/carbonEmi_downloaded.csv'\n",
    "carbon=pd.read_csv(linkToFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here it is:\n",
    "carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also\n",
    "carbon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency table\n",
    "carbon.region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency table\n",
    "carbon.date_of_information.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the tasks requested:\n",
    "\n",
    "1. Keep the columns _name_, _value_, *date_of_information* and _region_.\n",
    "    * Tip: use [drop](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html), [loc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html), and [iloc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html) for the same purpose (three ways to accomplish the task).\n",
    "2. Change the column name *date_of_information* to *carbon_date*.\n",
    "    * Tip: Use [rename](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html).\n",
    "3. Make sure the cells with text does not have neither trailing nor leading spaces.\n",
    "    * Tip: use [strip](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html).\n",
    "4. Detect the presence of symbols in the numeric data that are not numeric or point.\n",
    "    * Tip: Use [contains](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html).\n",
    "5. Make sure there are no spaces as part of the column names.\n",
    "    * Tip: use [replace](https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html).\n",
    "6. Get rid of any value detected in the previous step:\n",
    "    * Tip: use [replace](https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html).\n",
    "7. Keep only the year value in the column *carbon_date*.\n",
    "    * Tip: use [extract](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html).\n",
    "\n",
    "When all tasks are done, create a folder **data** inside the current folder, and save the cleaned file like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# carbonCleaned.to_csv(os.path.join(\"data\",\"carbonCleaned.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exercise 2: Scrape the data on [Revenue from forest resources](https://www.cia.gov/the-world-factbook/field/revenue-from-forest-resources/country-comparison). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame  \n",
    "ciaLink2=\"https://www.cia.gov/the-world-factbook/field/revenue-from-forest-resources/country-comparison\" \n",
    "IFrame(ciaLink2, width=900, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scrape that data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read web table into pandas DF\n",
    "import pandas as pd\n",
    "\n",
    "forestDFs=pd.read_html(ciaLink2, # link\n",
    "                        header=0, # where is the header?\n",
    "                        flavor='bs4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check object type \n",
    "type(forestDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check size\n",
    "len(forestDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a copy of that DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy\n",
    "forest=forestDFs[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here it is\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see column names:\n",
    "\n",
    "forest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or\n",
    "\n",
    "forest.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest['Date of Information'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the tasks requested:\n",
    "\n",
    "1. Replace '%' by 'pct'.\n",
    "    * Tip: use [replace](https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html).\n",
    "2. Keep the columns _Country_, _pct of GDP_, and *Date of Information*.\n",
    "    * Tip: use [drop](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html), [loc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html), and [iloc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html) for the same purpose (three ways to accomplish the task).\n",
    "3. Change the column name *Date of Information* to *forest_date*.\n",
    "    * Tip: Use [rename](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html).\n",
    "4. Make sure there are no spaces as part of the column names.\n",
    "    * Tip: use [replace](https://pandas.pydata.org/docs/reference/api/pandas.Series.replace.html).\n",
    "5. Make sure the cells with text does not have neither trailing nor leading spaces.\n",
    "    * Tip: use [strip](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html).\n",
    "6. Keep only the year value in the column *forest_date*.\n",
    "    * Tip: use [extract](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.extract.html).\n",
    "\n",
    "When all tasks are done, save the cleaned file inside your **data** folder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# forestCleaned.to_csv(os.path.join(\"data\",\"forestCleaned.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Geo Dataframe\n",
    "\n",
    "Let's see a  case of **maps represented by polygons**. Let me visit this page from the [World Bank](https://datacatalog.worldbank.org/search/dataset/0038272/World-Bank-Official-Boundaries). I have download the World Boundaries Low Resolution in GeoJSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, geopandas as gpd\n",
    "\n",
    "worldmap=gpd.read_file(os.path.join(\"maps\",\"WB_countries_Admin0_lowres.geojson\"))\n",
    "\n",
    "# see\n",
    "worldmap.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know you have a geodataframe when you have a **geometry column type**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldmap.geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame has several columns. Using **head()** is important to detect salient problems, but pandas or geopandas may hide some columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldmap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An strategy would be to see the head as an **html**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "display(HTML(worldmap.head().to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geometry column does not allow a clean visual of the data. Let's omit it and redo the previous code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(worldmap.drop(columns='geometry').to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are so many columns, it may be very hard to check each one for particular problems. In general, you need a clean map where you can add other data to it. The most important imformation will be in the data you add.\n",
    "Then, in this case, you will pay attention to the columns that are needed to combine this map and other data; that is, verify that the **key** or **identifiers** are clean. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any missin values?\n",
    "worldmap[worldmap.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data frame head, you may use these as identifiers of the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifiers=['TYPE','FORMAL_EN','FIPS_10_','ISO_A2', 'ISO_A3',\"ISO_A3_EH\"]\n",
    "worldmap.loc[:,identifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any repeated values in country name ('FORMAL_EN')?\n",
    "\n",
    "worldmap[worldmap.duplicated(subset=['FORMAL_EN'],keep=False)].drop(columns='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nice case of repeated values. Why would a map of countries repeat country names? \n",
    "Our first **guess** is that each row represents a polygon (a surface on the planet), so maybe a country may be composed of several polygons. But, we already saw the presence of **multipolygons** in a row. Then, it is possible that some polygons are differentiated for some international politics reason.\n",
    "\n",
    "In order to find out the nature of these findings we might need a closer look to the data. Let's use [dtale](https://github.com/man-group/dtale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dtale import show as dtshow\n",
    "\n",
    "\n",
    "dtshow(worldmap[worldmap.duplicated(subset=['FORMAL_EN'],keep=False)].drop(columns='geometry'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the map data is not perfect because of the complexity of international laws and the like. Notice the presence of \"-99\" and \"-099\". Those are representing a missing value. You may want to keep it that way as some map formats may not work as expected with missing values.\n",
    "\n",
    "Let's update our identifiers and create a new map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifiers=['TYPE','FORMAL_EN','WB_NAME','NAME_EN','FIPS_10_','ISO_A2', 'ISO_A3',\"ISO_A3_EH\",'ISO_N3','UN_A3',\"WB_A2\",'WB_A3','geometry']\n",
    "mapWorld=worldmap.loc[:,identifiers]\n",
    "\n",
    "#then\n",
    "mapWorld[mapWorld.duplicated(subset=['FORMAL_EN'],keep=False)].drop(columns='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a simpler map, it would be good to have a column with no repeated values in the ISO codes. That requires some research:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapWorld.loc[[234,235,236,249],'ISO_A2']=['BQ','BQ','BQ','TK']\n",
    "mapWorld.loc[[234,235,236,249],'ISO_A3']=['BQ1','BQ2','BQ3','TKL']\n",
    "mapWorld.loc[[234,235,236,249],'ISO_A3_EH']=['BQ1','BQ2','BQ3','TKL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems **WB_NAME** would be the best candidate for unique names. Let's verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapWorld[mapWorld.duplicated(subset=['WB_NAME'],keep=False)].drop(columns='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# on the missing ISOs?\n",
    "mapWorld[(mapWorld.loc[:,['ISO_A2','ISO_A3','ISO_A3_EH']].isin([\"-99\",\"-099\"])).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may call your attention the case of France, Norway and Kosovo. Let's solve those and some of the rest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly a mistake we need to solve (The Kosovo ISO3 came from [here](https://knowledgecenter.zuora.com/Quick_References/Country%2C_State%2C_and_Province_Codes/A_Country_Names_and_Their_ISO_Codes)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapWorld.loc[[20,50],'ISO_A2']=['FR','NO']\n",
    "mapWorld.loc[[20,50,62],'ISO_A3']=['FRA','NOR','XKX']\n",
    "mapWorld.loc[[50,62],'ISO_A3_EH']=['NOR','XKX']\n",
    "mapWorld.loc[[238,239,240,244,245,],'ISO_A3']= ['CCK','CXR','JTN','WAK',\"MID\"]\n",
    "mapWorld.loc[[238,239,240,244,245,],'ISO_A3_EH']= ['CCK','CXR','JTN','WAK',\"MID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recheck the repeated ISOs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapWorld[mapWorld.duplicated(subset=['ISO_A3'],keep=False)].drop(columns='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see npw the empty cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where=['TYPE','FORMAL_EN','WB_NAME','NAME_EN']\n",
    "mapWorld[(mapWorld.loc[:,where]==\" \").any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapWorld.loc[worldmap.FORMAL_EN.isin([\" \"]),'FORMAL_EN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can complete those cells with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapWorld.loc[worldmap.FORMAL_EN.isin([\" \"]),'WB_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting what we need:\n",
    "mapWorld.loc[worldmap.FORMAL_EN.isin([\" \"]),'WB_NAME'].str.replace('\\s\\(\\w+.\\)\\s*',\"\",regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then,\n",
    "newNames=mapWorld.loc[mapWorld.FORMAL_EN.isin([\" \"]),'WB_NAME'].str.replace('\\s\\(\\w+.\\)\\s*',\"\",regex=True)\n",
    "mapWorld.loc[mapWorld.FORMAL_EN.isin([\" \"]),'FORMAL_EN']=newNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming\n",
    "mapWorld[(mapWorld.loc[:,where]==\" \").any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking validity of geometries\n",
    "\n",
    "The way the geometry has been assembled might result in some serious problem if not solved before the analysis. Let's see if we have invalid geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapWorld[~mapWorld.is_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the invalid geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapWorld[~mapWorld.is_valid].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's solve this issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.validation import explain_validity, make_valid\n",
    "\n",
    "explain_validity(mapWorld[~mapWorld.is_valid].geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solving the issue:\n",
    "mapWorld.loc[174,'geometry']=make_valid(mapWorld.loc[174,'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapWorld[~mapWorld.is_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapWorld.to_file(os.path.join(\"maps\",\"mapWorld.gpkg\"), layer='countries', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "test"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
